**Our algorithm achieves Top3**

The prediction was made using the LightGBM model.

Due to some original features being harmful to prediction, such as buy-four price, buy-five price, sell-four price, sell-five price, etc., they have been removed from the features.

In feature engineering, we have taken into account both finance and mathematical statistics and constructed multiple evaluation indicators to reflect the rise and fall of stocks. To describe historical trends, a long short-term mean feature was constructed. To demonstrate the degree of data volatility, variance features were constructed. Considering that extreme points have a certain reflective effect on stocks, a maximum and minimum value feature was constructed. At the same time, the long short-term mean difference was constructed as an important golden cross in quantitative finance. Due to the consideration that the time sliding window of 100 ticks includes data before this time period (morning or day before), in some features, these data do not participate in the time sliding window. In the first 100 tickets of the test set, all data that cannot meet the sliding window length are set to NAN to avoid the statistical features being affected by extreme values due to insufficient sliding windows. This scheme is also adopted for the initial data of each time period (morning and afternoon) in some features.

In the model construction, the LightGBM model was selected for its fast training and prediction speed, low computational power requirements, and effectiveness in preventing overfitting. To address the negative impact of imbalanced samples in the label on prediction, the `class_weight` parameter was adjusted to better balance the issue of imbalanced samples.

In the prediction process, to meet the needs of practical quantitative finance and avoid relying on future data, a set of 100 tickets is used as input models in the prediction set. This set comprises the tickets to be predicted and the preceding 99 historical tickets. Features are derived from these 100 tickets to predict the current ticket. Real-time features are generated sequentially in chronological order during the data reading and prediction process, and then predictions are made. The prediction speed is significantly faster than a 3-second timestamp, and the computational power consumption is relatively low.
